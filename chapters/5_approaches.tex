\section{Approaches}

This section discusses the optimization of the enumerators with two different approaches in each case. In addition, a third approach evaluated is the avoidance of scanning unsupported services. 

\subsection{Use information of a former service scan}

This approach aims to reuse information from one enumerator in a later enumerator within the same scan. This will be applied to the RCEnumerator.

The Routine Control service is used by the client to execute a defined sequence of steps and obtain any relevant results \cite{iso14229}. For a quick overview of the service a simplified code snippet of the Scapy implementation is used.

\begin{samepage}
\begin{minted}{python}
class UDS_RC(Packet):
    routineControlTypes = {
        1: 'startRoutine',
        2: 'stopRoutine',
        3: 'requestResults'
    }
    fields_desc = [
        ByteEnumField('routineControlType', 0, routineControlTypes),
        XShortField('routineIdentifier', 0)
    ]
\end{minted}
\end{samepage}

The routineControlType field specifies what to do with a routine. Possible are starting, stopping and requesting the results. To specify which routine is to be controlled, there is the routineIdentifier field. Hence, there are three control types, and because the identifier is a short field, there are 2\textsuperscript{16} identifiers. This leads to the following formula, showing how many requests are generated for a UDS scan:
\[f(n)=3 * 2^{16} * n\]
wherin $n$ stands for the number of detected states.

The current RCEnumerator does exactly this, it generates the full range for each states. That's what needs to be reduced. Its current behavior is illustrated in \autoref{fig:rc-behavior-current}. The green areas show the scanned regions.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{rc-behavior-current}
    \caption{Behavior of the current RCEnumerator implementation.}
    \label{fig:rc-behavior-current}
\end{figure}

As a first step to find a way to apply the approach to the RCEnumerator, the distribution of the identifiers is visualized grouped by the type as a histogram in \autoref{fig:rc-distribution}.

% TODO: maybe to attachments
\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{rc-distribution}
    \caption{Distribution of the RC identifiers. Each color is one ECU.}
    \label{fig:rc-distribution}
\end{figure}

It can be seen that if an identifier is available in Type1, it is likely that this identifier also occurs in Type2. Consequently, if an identifier does not respond positively in Type1, it is also very unlikely that it will respond in Type2 or Type3. This appearance is used to reduce the scan range for this service.

The new behavior starts with scanning all 2\textsuperscript{16} identifiers with Type1. So, 2\textsuperscript{16} is the minimum number of requests for each state with the new behavior. Only the identifiers, which led to a positive response, are scanned with Type2 and Type3 as well. Moreover, it was observed that there seems to be a locality effect for the identifiers. Thus, if an identifier with Type1 is answered positively, scanning nearby identifiers instead of just that identifier will result in higher coverage. What needs to be found out is the block size which leads to the best coverage, while maintaining an appropriate speed-up.

The limits of the speed-up are defined as following:
\[ 0\ \% \ \leq\  s(n)\  \leq 66.\overline{66}\ \% \quad \forall \  n \in \left\{0, 1, ..., 2^{16} * 3\right\} \]
%\[ 0\  \ \leq\  s(n)\  \leq \frac{2}{3} \quad \forall \  n \in \left\{0, 1, ..., 2^{16 * 3}\right\} \]
wherin $s$ is the speed-up function and $n$ the number of generated requests.

The reason for the upper limit of $66.\overline{66}$ \% of this approach for this enumerator is because the first third is type1 and this is always scanned completely.

To find out the best value, scans with different block sizes are simulated. For a quick simulation another observation is used. If one identifier is available in one state, it is likely to be available in the other states too. Thus, the states are ignored in the simulation, which improves the performance by a multiple, while it is still very close to the real ECUs. The simulation only uses information gathered from the real ECUs as described in \autoref{sec:data-gathering}. Specifically, the required information is extracted from the generic.log file.

As described, the simulation starts with getting all identifiers which have been positively answered of the currently simulated ECU. Subsequently, these identifiers are expanded to blocks of the size from 1 to 200. Overlapping blocks are resolved to one continuous space. With these blocks the coverage and the number of requests can be calculated. The number of requests can be converted to the speed-up. The results are averaged.
The blocks are expanded in both directions. So, for example, if the identifier 500 has been answered positively and the block size is 100, it leads to range from 400 to 600. A simulation was also run with expanding individual identifiers in one direction only, which yielded very similar results. Thus, it was left with the expansion in both directions. 
The following pseudocode shows the procedure more clearly.

\begin{samepage}
\begin{minted}{python}
coverages = []
speedups = []
for block_width in range(200):
    coverages_block = []
    speedups_block = []
    for ecu in ecus:
        ids_type1 = get_type1_ids(ecu)
        to_scan = ids_to_block(ids_type1, block_width)
        coverages_block.append(get_coverage(ecu, to_scan))
        count_requests = len(to_scan)
        speedups_block.append(get_speedup(ecu, count_requests))
    coverages.append(avg(coverages_block))
    speedups.append(avg(speedups_block))
\end{minted}
\end{samepage}

The results of this simulation are plotted in \autoref{fig:rc-simulation-result}. The speed-up is linear to the block size. That makes sense, because the larger the blocks are, the more requests are generated, since the positively answered identifiers are independent of the block size. The block size of zero represents the results without using the locality effect. The maximum difference in coverage of with and without locality effect are 22\%, even though the maximum speed-up difference is only 1\%.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{rc-simulation-result}
    \caption{Simulation result for the RC service.}
    \label{fig:rc-simulation-result}
\end{figure}

Since the speed-up is high for each simulated block size, the highest coverage was chosen which starts with block size \textbf{132}. Hence, this value is the chosen and implemented block size.


\subsection{Reduction of scan range}
Most services are simpler and don't have a type as the RC service but only an identifier. So, reusing information within the same scan is limited. Here the second approach will be applied to reduce the scan range. The idea is to scan more heavily the blocks where positive behavior is more likely than others. The approach will be applied to the Read Data By Identifier (RDBI) enumerator.

The Read Data By Identifier service allows the client to request data record values from the server identified by one or more dataIdentifiers \cite{iso14229}. Again, for a quick overview of the service a simplified code snippet of the Scapy implementation is used.

\begin{samepage}
\begin{minted}{python}
class UDS_RDBI(Packet):
    fields_desc = [
        XShortField('identifier', 0)
    ]
\end{minted}
\end{samepage}

To specify which data record to retrieve, there is the identifier field. Hence, because the identifier is a short field, there are 2\textsuperscript{16} identifiers. This leads to the following formula, showing how many requests are generated for a UDS scan:
\[f(n)=2^{16} * n\]
wherin $n$ stands for the number of detected states. 

So, the current RDBIEnumerator is very simple. It generates 2\textsuperscript{16} packets counting up from 0 to 65535 and generating for each number a packet with this number as identifier for each state.

As a first step, the distribution of identifiers over all ECUs is visualized in a histogram, to check if there is potential. The result can be seen in \autoref{fig:rdbi-distribution}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{rdbi-distribution}
    \caption{Distribution of the RDBI identifiers. Each color is one ECU.}
    \label{fig:rdbi-distribution}
\end{figure}

It can be clearly seen that there are some areas where not a single identifier was answered positively, and some areas that are particularly covered, such as the beginning and the end. This behavior will be exploited in the remainder of this section.

As the procedure to reduce this range, first, the 2\textsuperscript{16} area has to be split up in blocks. Then, it is calculated how likely a positive response is for each of these blocks. Based on this information, the number of requests for each block will be calculated individually. For that, the probability is multiplied with the block size.
\[c(p, s)=\max(p * s, 1)\]
wherin p stands for the probability of the requested block and s for the block size. For each block should be generated at least one request. The requested identifiers within one block are generated randomly. If any of these requests is answered positively in a block, the whole block will be scanned.
This leads to one question. Which block size leads to best results? This is again answered in a simulation.

The simulation is performed for every possible block size, as such block sizes of $2^2, 2^3, ..., 2^{15}, 2^{16}$ are chosen because they are divisors for 2\textsuperscript{16}. For the current block size to simulate the probabilities for each block are calculated based on all ECUs together. The resulting coverage and speed-up are then calculated for each ECU specifically and averaged. The approach has one more feature which makes the simulation more complex than the former simulation. Since the blocks are first scanned randomly, the scan can lead to a great coverage, but also a low one, depending on the goodness of the generated identifiers. To reduce this effect, the calculation of the coverage and speed-up are made 100 times, each time with newly created identifiers. The 100 resulting values are averaged to the value corrected from the random factor.
The following pseudocode shows the procedure more clearly.

\begin{samepage}
\begin{minted}{python}
for exponent in range(2, 16):
    block_size = 2 ** exponent
    coverages = []
    samples = []
    probabilities = get_probabilities(ecus, block_size)
    for ecu in ecus:
        for i in range(100):
            samples = random_samples(block_size, probabilities)
            positive_identifiers = ecu.get_positive_identifiers(samples)
            block_list = to_blocks(positive_identifiers, block_size)
            positive_identifiers = ecu.get_positive_identifiers(block_list)

            coverages.append(get_coverage(ecu, positive_identifiers))
            samples.append(len(block_list))
        avg_coverages, avg_samples = avg(coverages, samples)
\end{minted}
\end{samepage}

This simulation leads to \autoref{fig:rdbi-simulation-result}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{rdbi-simulation-result}
    \caption{Simulation result for the RDBI service.}
    \label{fig:rdbi-simulation-result}
\end{figure}

The speed-up is not linear anymore, instead, the speed-up is the highest in the medium block sizes. From block sizes 64 to 128, the coverage decreases by 4\% while the speed-up remains the same. Thus, it was decided for \textbf{64} as the block size leading to best results.



\subsection{Avoid the scan of unsupported services}
